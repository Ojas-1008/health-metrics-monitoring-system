{
  "timestamp": "2025-11-21T00:24:21.500973",
  "batch_id": "test-batch-001",
  "error_message": "An error occurred while calling o52.count.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2) (Ojas executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:612)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:594)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:789)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithoutKey_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.EOFException\r\n\tat java.io.DataInputStream.readInt(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\t... 25 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:612)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:594)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:789)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithoutKey_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.EOFException\r\n\tat java.io.DataInputStream.readInt(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\r\n\t... 25 more\r\n",
  "record_count": 6,
  "failed_records": [
    {
      "userId": "673f39c6b4f1e40b3c123456",
      "metricType": "steps",
      "timeRange": "7day",
      "analytics": {
        "rollingAverage": 7500.0,
        "trend": "up",
        "trendPercentage": 12.5,
        "anomalyDetected": false,
        "anomalyDetails": null,
        "streakDays": 5,
        "longestStreak": 14,
        "streakStartDate": "2025-11-16 00:24:03.932638",
        "percentile": 75.0,
        "comparisonToPrevious": {
          "absoluteChange": 850.0,
          "percentageChange": 12.5,
          "isImprovement": true
        },
        "statistics": {
          "standardDeviation": 1250.0,
          "minValue": 4500.0,
          "maxValue": 12000.0,
          "medianValue": 7200.0,
          "dataPointsCount": 7,
          "completenessPercentage": 85.7
        }
      },
      "calculatedAt": "2025-11-21 00:24:03.932657",
      "expiresAt": "2026-02-19 00:24:03.932657",
      "metadata": {
        "sparkJobId": "test-job-001",
        "processingDurationMs": 1500,
        "dataPointsProcessed": 100,
        "sparkVersion": "3.5.0"
      }
    },
    {
      "userId": "673f39c6b4f1e40b3c123456",
      "metricType": "steps",
      "timeRange": "30day",
      "analytics": {
        "rollingAverage": 7500.0,
        "trend": "up",
        "trendPercentage": 12.5,
        "anomalyDetected": false,
        "anomalyDetails": null,
        "streakDays": 5,
        "longestStreak": 14,
        "streakStartDate": "2025-11-16 00:24:03.933311",
        "percentile": 75.0,
        "comparisonToPrevious": {
          "absoluteChange": 850.0,
          "percentageChange": 12.5,
          "isImprovement": true
        },
        "statistics": {
          "standardDeviation": 1250.0,
          "minValue": 4500.0,
          "maxValue": 12000.0,
          "medianValue": 7200.0,
          "dataPointsCount": 30,
          "completenessPercentage": 90.0
        }
      },
      "calculatedAt": "2025-11-21 00:24:03.933351",
      "expiresAt": "2026-02-19 00:24:03.933352",
      "metadata": {
        "sparkJobId": "test-job-001",
        "processingDurationMs": 1500,
        "dataPointsProcessed": 100,
        "sparkVersion": "3.5.0"
      }
    },
    {
      "userId": "673f39c6b4f1e40b3c123456",
      "metricType": "calories",
      "timeRange": "7day",
      "analytics": {
        "rollingAverage": 2500.0,
        "trend": "up",
        "trendPercentage": 12.5,
        "anomalyDetected": false,
        "anomalyDetails": null,
        "streakDays": 5,
        "longestStreak": 14,
        "streakStartDate": "2025-11-16 00:24:03.933716",
        "percentile": 75.0,
        "comparisonToPrevious": {
          "absoluteChange": 850.0,
          "percentageChange": 12.5,
          "isImprovement": true
        },
        "statistics": {
          "standardDeviation": 1250.0,
          "minValue": 4500.0,
          "maxValue": 12000.0,
          "medianValue": 7200.0,
          "dataPointsCount": 7,
          "completenessPercentage": 85.7
        }
      },
      "calculatedAt": "2025-11-21 00:24:03.933731",
      "expiresAt": "2026-02-19 00:24:03.933732",
      "metadata": {
        "sparkJobId": "test-job-001",
        "processingDurationMs": 1500,
        "dataPointsProcessed": 100,
        "sparkVersion": "3.5.0"
      }
    },
    {
      "userId": "673f39c6b4f1e40b3c123456",
      "metricType": "calories",
      "timeRange": "30day",
      "analytics": {
        "rollingAverage": 2500.0,
        "trend": "up",
        "trendPercentage": 12.5,
        "anomalyDetected": false,
        "anomalyDetails": null,
        "streakDays": 5,
        "longestStreak": 14,
        "streakStartDate": "2025-11-16 00:24:03.934010",
        "percentile": 75.0,
        "comparisonToPrevious": {
          "absoluteChange": 850.0,
          "percentageChange": 12.5,
          "isImprovement": true
        },
        "statistics": {
          "standardDeviation": 1250.0,
          "minValue": 4500.0,
          "maxValue": 12000.0,
          "medianValue": 7200.0,
          "dataPointsCount": 30,
          "completenessPercentage": 90.0
        }
      },
      "calculatedAt": "2025-11-21 00:24:03.934021",
      "expiresAt": "2026-02-19 00:24:03.934022",
      "metadata": {
        "sparkJobId": "test-job-001",
        "processingDurationMs": 1500,
        "dataPointsProcessed": 100,
        "sparkVersion": "3.5.0"
      }
    },
    {
      "userId": "673f39c6b4f1e40b3c123456",
      "metricType": "distance",
      "timeRange": "7day",
      "analytics": {
        "rollingAverage": 2500.0,
        "trend": "up",
        "trendPercentage": 12.5,
        "anomalyDetected": false,
        "anomalyDetails": null,
        "streakDays": 5,
        "longestStreak": 14,
        "streakStartDate": "2025-11-16 00:24:03.934279",
        "percentile": 75.0,
        "comparisonToPrevious": {
          "absoluteChange": 850.0,
          "percentageChange": 12.5,
          "isImprovement": true
        },
        "statistics": {
          "standardDeviation": 1250.0,
          "minValue": 4500.0,
          "maxValue": 12000.0,
          "medianValue": 7200.0,
          "dataPointsCount": 7,
          "completenessPercentage": 85.7
        }
      },
      "calculatedAt": "2025-11-21 00:24:03.934290",
      "expiresAt": "2026-02-19 00:24:03.934291",
      "metadata": {
        "sparkJobId": "test-job-001",
        "processingDurationMs": 1500,
        "dataPointsProcessed": 100,
        "sparkVersion": "3.5.0"
      }
    },
    {
      "userId": "673f39c6b4f1e40b3c123456",
      "metricType": "distance",
      "timeRange": "30day",
      "analytics": {
        "rollingAverage": 2500.0,
        "trend": "up",
        "trendPercentage": 12.5,
        "anomalyDetected": false,
        "anomalyDetails": null,
        "streakDays": 5,
        "longestStreak": 14,
        "streakStartDate": "2025-11-16 00:24:03.934591",
        "percentile": 75.0,
        "comparisonToPrevious": {
          "absoluteChange": 850.0,
          "percentageChange": 12.5,
          "isImprovement": true
        },
        "statistics": {
          "standardDeviation": 1250.0,
          "minValue": 4500.0,
          "maxValue": 12000.0,
          "medianValue": 7200.0,
          "dataPointsCount": 30,
          "completenessPercentage": 90.0
        }
      },
      "calculatedAt": "2025-11-21 00:24:03.934605",
      "expiresAt": "2026-02-19 00:24:03.934605",
      "metadata": {
        "sparkJobId": "test-job-001",
        "processingDurationMs": 1500,
        "dataPointsProcessed": 100,
        "sparkVersion": "3.5.0"
      }
    }
  ]
}